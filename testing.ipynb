{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7fXKU_7Bl2t",
        "outputId": "328a2a2b-a60d-44b6-dbcc-88817fb58995"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl (30.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m60.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate a sample test_set using the provided document metadata context\n",
        "\n",
        "test_set = [\n",
        "    {\n",
        "        \"question\": \"What are the early symptoms of Acute Lymphoblastic Leukemia?\",\n",
        "        \"ground_truth_source\": \"processed-text/documents/CancerGov_0000001_1.txt\",\n",
        "        \"ground_truth_answer\": (\n",
        "            \"Early symptoms include fatigue, fever, easy bruising or bleeding, petechiae, \"\n",
        "            \"shortness of breath, weight loss, and frequent infections.\"\n",
        "        ),\n",
        "        \"relevance_mapping\": {\n",
        "            \"processed-text/documents/CancerGov_0000001_1.txt\": 3\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"How is Acute Lymphoblastic Leukemia diagnosed?\",\n",
        "        \"ground_truth_source\": \"processed-text/documents/CancerGov_0000001_1.txt\",\n",
        "        \"ground_truth_answer\": (\n",
        "            \"Diagnosis is made using tests such as complete blood count (CBC), blood chemistry, \"\n",
        "            \"bone marrow biopsy, cytogenetic analysis, immunophenotyping, and lumbar puncture.\"\n",
        "        ),\n",
        "        \"relevance_mapping\": {\n",
        "            \"processed-text/documents/CancerGov_0000001_1.txt\": 3\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"What are the treatment phases of Acute Lymphoblastic Leukemia?\",\n",
        "        \"ground_truth_source\": \"processed-text/documents/CancerGov_0000001_1.txt\",\n",
        "        \"ground_truth_answer\": (\n",
        "            \"The treatment includes remission induction therapy, consolidation therapy, and CNS prophylaxis, \"\n",
        "            \"with chemotherapy and sometimes radiation.\"\n",
        "        ),\n",
        "        \"relevance_mapping\": {\n",
        "            \"processed-text/documents/CancerGov_0000001_1.txt\": 3\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"Which genetic disorders are associated with a higher risk of childhood ALL?\",\n",
        "        \"ground_truth_source\": \"processed-text/documents/CancerGov_0000001_6.txt\",\n",
        "        \"ground_truth_answer\": (\n",
        "            \"Genetic disorders like Down syndrome, neurofibromatosis type 1, Bloom syndrome, \"\n",
        "            \"Fanconi anemia, ataxia-telangiectasia, and Li-Fraumeni syndrome are associated with higher risk.\"\n",
        "        ),\n",
        "        \"relevance_mapping\": {\n",
        "            \"processed-text/documents/CancerGov_0000001_6.txt\": 3\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"What is the role of BRCA1 and BRCA2 in prostate cancer?\",\n",
        "        \"ground_truth_source\": \"processed-text/documents/GHR_0000836.txt\",\n",
        "        \"ground_truth_answer\": (\n",
        "            \"BRCA1 and BRCA2 genes help repair damaged DNA. Mutations impair this function, increasing prostate cancer risk.\"\n",
        "        ),\n",
        "        \"relevance_mapping\": {\n",
        "            \"processed-text/documents/GHR_0000836.txt\": 3\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"What causes Protein C Deficiency?\",\n",
        "        \"ground_truth_source\": \"processed-text/documents/GHR_0000837.txt\",\n",
        "        \"ground_truth_answer\": (\n",
        "            \"Protein C deficiency is caused by mutations in the PROC gene, leading to reduced or altered protein C, affecting blood clot regulation.\"\n",
        "        ),\n",
        "        \"relevance_mapping\": {\n",
        "            \"processed-text/documents/GHR_0000837.txt\": 3\n",
        "        }\n",
        "    }\n",
        "\n",
        "]\n",
        "\n",
        "import json\n",
        "import os\n",
        "\n",
        "# Save the test_set to a JSON file for later evaluation\n",
        "output_path = \"test_set.json\"\n",
        "with open(output_path, \"w\") as f:\n",
        "    json.dump(test_set, f, indent=2)\n",
        "\n",
        "output_path\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "TOEU8nS1PyNP",
        "outputId": "9142f6d5-10b6-4bd0-e8be-a5d649240755"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'test_set.json'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import json\n",
        "import numpy as np\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "from sentence_transformers import CrossEncoder, SentenceTransformer\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "import faiss\n",
        "\n",
        "# Paths and model names\n",
        "FAISS_INDEX_PATH = \"faiss_doc_index_384.bin\"\n",
        "FAISS_METADATA_PATH = \"faiss_doc_metadata.json\"\n",
        "TEST_SET_PATH = \"test_set.json\"\n",
        "LLM_MODEL_ID = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
        "BI_ENCODER_LOCAL = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "CROSS_ENCODER_MODEL = \"cross-encoder/ms-marco-MiniLM-L-6-v2\"\n",
        "\n",
        "# Load FAISS index and metadata\n",
        "def load_faiss():\n",
        "    index = faiss.read_index(FAISS_INDEX_PATH)\n",
        "    with open(FAISS_METADATA_PATH, \"r\", encoding=\"utf-8\") as f:\n",
        "        metadata = json.load(f)\n",
        "    return index, metadata\n",
        "\n",
        "# Embedding and reranking\n",
        "def get_embedding(text, encoder):\n",
        "    emb = encoder.encode(text, convert_to_numpy=True)\n",
        "    if emb.ndim == 1:\n",
        "        emb = emb[np.newaxis, :]\n",
        "    return emb.astype(\"float32\")\n",
        "\n",
        "def rerank_local(query, candidates, cross_encoder, top_n=None):\n",
        "    pairs = [[query, c[\"text\"]] for c in candidates]\n",
        "    scores = cross_encoder.predict(pairs)\n",
        "    for c, score in zip(candidates, scores):\n",
        "        c[\"rerank_score\"] = float(score)\n",
        "    sorted_hits = sorted(candidates, key=lambda x: x[\"rerank_score\"], reverse=True)\n",
        "    return sorted_hits if top_n is None else sorted_hits[:top_n]\n",
        "\n",
        "def search_faiss(query, faiss_index, metadata, bi_encoder, cross_encoder, top_k=10, rerank_top_k=5):\n",
        "    q_emb = get_embedding(query, bi_encoder)\n",
        "    distances, indices = faiss_index.search(q_emb, top_k)\n",
        "\n",
        "    seen = set()\n",
        "    results = []\n",
        "    for i in range(top_k):\n",
        "        idx = indices[0][i]\n",
        "        dist = distances[0][i]\n",
        "        meta = metadata[idx]\n",
        "        doc_id = meta.get(\"source\")\n",
        "        chunk_id = meta.get(\"chunk_id\")\n",
        "        key = (doc_id, chunk_id)\n",
        "        if key in seen:\n",
        "            continue\n",
        "        seen.add(key)\n",
        "        results.append({\n",
        "            \"rank\": len(results) + 1,\n",
        "            \"score\": float(dist),\n",
        "            \"source\": doc_id,\n",
        "            \"chunk_id\": chunk_id,\n",
        "            \"text\": meta.get(\"text\")\n",
        "        })\n",
        "\n",
        "    return rerank_local(query, results, cross_encoder, top_n=rerank_top_k)\n",
        "\n",
        "# Answer generation\n",
        "def answer(question, context, model, tokenizer):\n",
        "    prompt = (\n",
        "        \"<|system|>You are a helpful and knowledgeable medical assistant.<|end|>\\n\"\n",
        "        f\"<|user|>Context:\\n{context}\\n\\nQuestion: {question}<|end|>\\n\"\n",
        "        f\"<|assistant|>The answer is:\"\n",
        "    )\n",
        "\n",
        "    generator = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
        "    response = generator(\n",
        "        prompt,\n",
        "        max_new_tokens=150,\n",
        "        temperature=0.7,\n",
        "        do_sample=True,\n",
        "        top_p=0.9,\n",
        "        top_k=40\n",
        "    )\n",
        "\n",
        "    parts = response[0][\"generated_text\"].split(\"<|assistant|>The answer is:\")\n",
        "    return parts[1].strip() if len(parts) > 1 else \"Could not extract answer\"\n",
        "\n",
        "# Evaluation metrics\n",
        "def compute_mrr(results, ground_truth_source):\n",
        "    for i, r in enumerate(results):\n",
        "        if r[\"source\"] == ground_truth_source:\n",
        "            return 1 / (i + 1)\n",
        "    return 0\n",
        "\n",
        "def ndcg(relevances, k=5):\n",
        "    dcg = sum(rel / np.log2(i + 2) for i, rel in enumerate(relevances[:k]))\n",
        "    ideal = sorted(relevances, reverse=True)\n",
        "    idcg = sum(rel / np.log2(i + 2) for i, rel in enumerate(ideal[:k]))\n",
        "    return dcg / idcg if idcg > 0 else 0\n",
        "\n",
        "def compute_bleu(reference, candidate):\n",
        "    smoothie = SmoothingFunction().method4\n",
        "    return sentence_bleu([reference.split()], candidate.split(), smoothing_function=smoothie)\n",
        "\n",
        "# Run evaluation\n",
        "def evaluate(test_set):\n",
        "    faiss_index, metadata = load_faiss()\n",
        "    bi_encoder = SentenceTransformer(BI_ENCODER_LOCAL)\n",
        "    cross_encoder = CrossEncoder(CROSS_ENCODER_MODEL)\n",
        "    tokenizer = AutoTokenizer.from_pretrained(LLM_MODEL_ID)\n",
        "    model = AutoModelForCausalLM.from_pretrained(LLM_MODEL_ID)\n",
        "\n",
        "    latencies, mrr_scores, ndcg_scores, bleu_scores = [], [], [], []\n",
        "    eval_logs = []\n",
        "\n",
        "    for q in test_set:\n",
        "        start = time.time()\n",
        "        results = search_faiss(q[\"question\"], faiss_index, metadata, bi_encoder, cross_encoder)\n",
        "        context = \"\\n\\n\".join([r[\"text\"][:500] for r in results[:3]])\n",
        "        generated = answer(q[\"question\"], context, model, tokenizer)\n",
        "        end = time.time()\n",
        "\n",
        "        latencies.append(end - start)\n",
        "        mrr_scores.append(compute_mrr(results, q[\"ground_truth_source\"]))\n",
        "        relevances = [q[\"relevance_mapping\"].get(r[\"source\"], 0) for r in results]\n",
        "        ndcg_scores.append(ndcg(relevances))\n",
        "        bleu_scores.append(compute_bleu(q[\"ground_truth_answer\"], generated))\n",
        "\n",
        "        eval_logs.append({\n",
        "            \"question\": q[\"question\"],\n",
        "            \"answer\": generated,\n",
        "            \"reference\": q[\"ground_truth_answer\"],\n",
        "            \"latency\": end - start,\n",
        "            \"mrr\": mrr_scores[-1],\n",
        "            \"ndcg\": ndcg_scores[-1],\n",
        "            \"bleu\": bleu_scores[-1]\n",
        "        })\n",
        "\n",
        "    summary = {\n",
        "        \"Average Latency\": np.mean(latencies),\n",
        "        \"MRR\": np.mean(mrr_scores),\n",
        "        \"NDCG\": np.mean(ndcg_scores),\n",
        "        \"BLEU\": np.mean(bleu_scores)\n",
        "    }\n",
        "\n",
        "    # Save detailed logs\n",
        "    with open(\"detailed_eval_log.json\", \"w\") as f:\n",
        "        json.dump(eval_logs, f, indent=2)\n",
        "\n",
        "    return summary\n",
        "\n",
        "# Load test set and run evaluation\n",
        "with open(TEST_SET_PATH, \"r\") as f:\n",
        "    test_set = json.load(f)\n",
        "\n",
        "metrics_summary = evaluate(test_set)\n",
        "print(metrics_summary)\n",
        "metrics_summary_path = \"metrics_summary.json\"\n",
        "with open(metrics_summary_path, \"w\") as f:\n",
        "    json.dump(metrics_summary, f, indent=2)\n",
        "\n",
        "metrics_summary_path\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "Y4gOhXrWReFG",
        "outputId": "ee2fd950-8173-42db-db01-c3b0736158e4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n",
            "Device set to use cuda:0\n",
            "Device set to use cuda:0\n",
            "Device set to use cuda:0\n",
            "Device set to use cuda:0\n",
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Average Latency': np.float64(3.528817892074585), 'MRR': np.float64(0.7000000000000001), 'NDCG': np.float64(0.7257201317872851), 'BLEU': np.float64(0.04633737565877292)}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'metrics_summary.json'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    }
  ]
}